[openai]
model = "gpt-4.1-mini"
temperature = 0.2
max_output_tokens = 600

[demo]
cache_enabled = true
